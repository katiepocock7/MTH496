{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function:$b+xc^T$\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_{i=1}^n c_i^2 + \\lambda \\sum_{i=1}^M \\text{max}(0,1-y^{(i)}(b+x^{(i)}c^T))\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X, y, epochs, lr, lam):\n",
    "    b = 1.\n",
    "    c = np.ones(X.shape[1])\n",
    "    # gradient descent\n",
    "    for epoch in range(epochs): \n",
    "        hinge_loss = 1. - y * (b + np.dot(X, c))\n",
    "        hinge_loss[hinge_loss <= 1e-5] = 0 # hinge loss\n",
    "        dc = - lam * np.dot(y[hinge_loss != 0], X[hinge_loss !=0]) + 2.*c\n",
    "        db = - lam * np.sum(y[hinge_loss != 0])\n",
    "        c -= lr * dc\n",
    "        b -= lr * db\n",
    "    return b, c\n",
    "\n",
    "def accuracy(ypred, yreal):\n",
    "    return np.sum(ypred==yreal)/float(len(yreal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Xtrain is (2000, 784)\n",
      "The shape of ytrain is (2000, 1)\n",
      "The shape of Xtest is (500, 784)\n",
      "The shape of ytest is (500, 1)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = pd.read_csv(\"MNIST_X_train.csv\").values\n",
    "ytrain = pd.read_csv(\"MNIST_Y_train.csv\").values\n",
    "Xtest = pd.read_csv(\"MNIST_X_test.csv\").values\n",
    "ytest = pd.read_csv(\"MNIST_Y_test.csv\").values\n",
    "\n",
    "print(\"The shape of Xtrain is {}\".format(Xtrain.shape))\n",
    "print(\"The shape of ytrain is {}\".format(ytrain.shape))\n",
    "print(\"The shape of Xtest is {}\".format(Xtest.shape))\n",
    "print(\"The shape of ytest is {}\".format(ytest.shape))\n",
    "\n",
    "ytrain, ytest = ytrain.flatten(), ytest.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer(neg_label=-1)\n",
    "lb.fit(ytrain)\n",
    "ytrain_ohe = lb.transform(ytrain)\n",
    "ytest_ohe  = lb.transform(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class 0 vs all is complete. The training accuracy is 98.65%\n",
      "Training class 1 vs all is complete. The training accuracy is 99.10%\n",
      "Training class 2 vs all is complete. The training accuracy is 98.35%\n",
      "Training class 3 vs all is complete. The training accuracy is 97.25%\n",
      "Training class 4 vs all is complete. The training accuracy is 98.90%\n",
      "Training class 5 vs all is complete. The training accuracy is 97.30%\n",
      "Training class 6 vs all is complete. The training accuracy is 98.45%\n",
      "Training class 7 vs all is complete. The training accuracy is 98.25%\n",
      "Training class 8 vs all is complete. The training accuracy is 96.25%\n",
      "Training class 9 vs all is complete. The training accuracy is 93.85%\n",
      "The accuracy of multiclass classification is 88.40%\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler().fit(Xtrain)\n",
    "scaled_Xtrain = scaler.transform(Xtrain)\n",
    "scaled_Xtest = scaler.transform(Xtest)\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.03\n",
    "lam = 1/200 # lambda\n",
    "      \n",
    "preds = np.zeros((Xtest.shape[0], 10))\n",
    "# one vs all approach\n",
    "for i in range(10):\n",
    "    # Train class i vs rest\n",
    "    b, c = SVM(scaled_Xtrain, ytrain_ohe[:,i], epochs, lr, lam)\n",
    "    preds[:, i] = np.dot(scaled_Xtest, c)+b # labels is going to be used for prediction on test data\n",
    "    \n",
    "    pred_labels = np.dot(scaled_Xtrain, c)+b \n",
    "    pred_labels[pred_labels < 0.] = -1\n",
    "    pred_labels[pred_labels >= 0.] = 1 # pred_labels are the labels predicted on training data\n",
    "    # compute training accuracy\n",
    "    score = accuracy(ytrain_ohe[:,i], pred_labels)\n",
    "    print(\"Training class {} vs all is complete. The training accuracy is {:.2f}%\".format(i, score*100))\n",
    "\n",
    "ypred = np.argmax(preds, axis=1)\n",
    "\n",
    "score = accuracy(ytest, ypred)\n",
    "print(\"The accuracy of multiclass classification is {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0,1])\n",
    "B = np.array([[0,1],[2,3]])\n",
    "np.dot(a, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class 0 vs class 1 is complete. The training accuracy is 100.00%\n",
      "Training class 0 vs class 2 is complete. The training accuracy is 99.05%\n",
      "Training class 0 vs class 3 is complete. The training accuracy is 98.05%\n",
      "Training class 0 vs class 4 is complete. The training accuracy is 99.75%\n",
      "Training class 0 vs class 5 is complete. The training accuracy is 99.23%\n",
      "Training class 0 vs class 6 is complete. The training accuracy is 100.00%\n",
      "Training class 0 vs class 7 is complete. The training accuracy is 99.76%\n",
      "Training class 0 vs class 8 is complete. The training accuracy is 98.68%\n",
      "Training class 0 vs class 9 is complete. The training accuracy is 99.49%\n",
      "Training class 1 vs class 2 is complete. The training accuracy is 98.00%\n",
      "Training class 1 vs class 3 is complete. The training accuracy is 97.05%\n",
      "Training class 1 vs class 4 is complete. The training accuracy is 99.54%\n",
      "Training class 1 vs class 5 is complete. The training accuracy is 98.80%\n",
      "Training class 1 vs class 6 is complete. The training accuracy is 99.77%\n",
      "Training class 1 vs class 7 is complete. The training accuracy is 99.11%\n",
      "Training class 1 vs class 8 is complete. The training accuracy is 97.30%\n",
      "Training class 1 vs class 9 is complete. The training accuracy is 99.52%\n",
      "Training class 2 vs class 3 is complete. The training accuracy is 97.12%\n",
      "Training class 2 vs class 4 is complete. The training accuracy is 99.03%\n",
      "Training class 2 vs class 5 is complete. The training accuracy is 99.49%\n",
      "Training class 2 vs class 6 is complete. The training accuracy is 99.26%\n",
      "Training class 2 vs class 7 is complete. The training accuracy is 99.76%\n",
      "Training class 2 vs class 8 is complete. The training accuracy is 97.66%\n",
      "Training class 2 vs class 9 is complete. The training accuracy is 99.75%\n",
      "Training class 3 vs class 4 is complete. The training accuracy is 99.50%\n",
      "Training class 3 vs class 5 is complete. The training accuracy is 97.15%\n",
      "Training class 3 vs class 6 is complete. The training accuracy is 99.75%\n",
      "Training class 3 vs class 7 is complete. The training accuracy is 99.28%\n",
      "Training class 3 vs class 8 is complete. The training accuracy is 96.53%\n",
      "Training class 3 vs class 9 is complete. The training accuracy is 98.97%\n",
      "Training class 4 vs class 5 is complete. The training accuracy is 99.47%\n",
      "Training class 4 vs class 6 is complete. The training accuracy is 99.49%\n",
      "Training class 4 vs class 7 is complete. The training accuracy is 98.05%\n",
      "Training class 4 vs class 8 is complete. The training accuracy is 98.37%\n",
      "Training class 4 vs class 9 is complete. The training accuracy is 96.34%\n",
      "Training class 5 vs class 6 is complete. The training accuracy is 99.73%\n",
      "Training class 5 vs class 7 is complete. The training accuracy is 99.24%\n",
      "Training class 5 vs class 8 is complete. The training accuracy is 95.47%\n",
      "Training class 5 vs class 9 is complete. The training accuracy is 98.91%\n",
      "Training class 6 vs class 7 is complete. The training accuracy is 99.75%\n",
      "Training class 6 vs class 8 is complete. The training accuracy is 98.08%\n",
      "Training class 6 vs class 9 is complete. The training accuracy is 99.73%\n",
      "Training class 7 vs class 8 is complete. The training accuracy is 99.22%\n",
      "Training class 7 vs class 9 is complete. The training accuracy is 96.21%\n",
      "Training class 8 vs class 9 is complete. The training accuracy is 98.87%\n",
      "The accuracy of multiclass classification is 89.60%\n"
     ]
    }
   ],
   "source": [
    "# A more concise version of one vs one classification\n",
    "# Feature scaling\n",
    "scaler = StandardScaler().fit(Xtrain)\n",
    "scaler.fit(Xtrain)\n",
    "scaled_Xtrain = scaler.transform(Xtrain)\n",
    "scaled_Xtest = scaler.transform(Xtest)\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.03\n",
    "lam = 1/200 # lambda\n",
    "\n",
    "labels = np.zeros((Xtest.shape[0], 10))\n",
    "# one vs one approach\n",
    "for i in range(9):\n",
    "    for j in range(10):\n",
    "        if j > i:\n",
    "            data = scaled_Xtrain[(ytrain_ohe[:, i]==1)+(ytrain_ohe[:, j]==1)] # False+False=False\n",
    "            target = ytrain_ohe[:,i][(ytrain_ohe[:, i]==1)+(ytrain_ohe[:, j]==1)]\n",
    "            # Train class i vs class j\n",
    "            b, c = SVM(data, target, epochs, lr, lam)\n",
    "            \n",
    "            labels_training_sets = np.dot(data, c)+b \n",
    "            labels_training_sets[labels_training_sets >=1e-5] = 1\n",
    "            labels_training_sets[labels_training_sets < 1e-5] = -1 # labels predicted on training sets\n",
    "            # compute training accuracy\n",
    "            score = accuracy(target, labels_training_sets)\n",
    "            print(\"Training class {} vs class {} is complete. The training accuracy is {:.2f}%\".format(i,j,score*100))\n",
    "            \n",
    "            pred = np.dot(scaled_Xtest, c)+b\n",
    "            labels[:, i][pred>=1e-5] += 1\n",
    "            labels[:, j][pred<1e-5] += 1\n",
    "\n",
    "ypred = np.argmax(labels, axis=1)\n",
    "\n",
    "score = accuracy(ytest, ypred)\n",
    "print(\"The accuracy of multiclass classification is {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ytrain_ohe[:, i]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b9baf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(2)+np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b83bad6c4b5a78a13893782ab5f14b2b670f5dde44611c21ac35ec8ddfbed47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
